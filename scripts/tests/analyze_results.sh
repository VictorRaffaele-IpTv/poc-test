#!/bin/bash

# Script de AnÃ¡lise dos Resultados de Performance
# Consolida e analisa todos os testes executados

set -e

RESULTS_DIR="load_test_results"
AB_RESULTS_DIR="ab_test_results"
MONITOR_RESULTS_DIR="monitoring_results"

# Cores
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[$(date +'%H:%M:%S')] $1${NC}"
}

# Analisar resultados dos testes de carga
analyze_load_tests() {
    echo -e "${BLUE}ğŸ“Š AnÃ¡lise dos Testes de Carga${NC}"
    echo "================================="
    echo ""
    
    if [ ! -d "$RESULTS_DIR" ] || [ -z "$(ls -A $RESULTS_DIR 2>/dev/null)" ]; then
        echo "âŒ Nenhum resultado de teste de carga encontrado em $RESULTS_DIR"
        return
    fi
    
    echo "ğŸ“‹ Resumo Executivo:"
    echo ""
    
    # Analisar cada arquivo de teste
    for test_file in $RESULTS_DIR/curl_load_*.txt; do
        if [ -f "$test_file" ]; then
            local filename=$(basename $test_file)
            local users=$(echo $filename | grep -o '[0-9]\+users' | sed 's/users//')
            local requests=$(echo $filename | grep -o '[0-9]\+req' | sed 's/req//')
            
            echo "ğŸ”¸ Teste: $users usuÃ¡rios, $requests req/usuÃ¡rio"
            
            # Extrair mÃ©tricas principais
            local total_requests=$(grep "RequisiÃ§Ãµes totais:" $test_file | cut -d: -f2 | tr -d ' ')
            local p50=$(grep "P50:" $test_file | cut -d: -f2 | tr -d ' s')
            local p95=$(grep "P95:" $test_file | cut -d: -f2 | tr -d ' s')
            local min_time=$(grep "MÃ­nimo:" $test_file | cut -d: -f2 | tr -d ' s')
            local max_time=$(grep "MÃ¡ximo:" $test_file | cut -d: -f2 | tr -d ' s')
            
            # CÃ³digos de resposta
            local success_codes=$(grep -E " 200$| 201$" $test_file | awk '{sum += $1} END {print sum}' || echo "0")
            local error_codes=$(grep -E " [45][0-9][0-9]$" $test_file | awk '{sum += $1} END {print sum}' || echo "0")
            
            echo "   Total: $total_requests requisiÃ§Ãµes"
            echo "   Sucesso: $success_codes ($(echo "scale=1; $success_codes * 100 / $total_requests" | bc -l 2>/dev/null || echo "N/A")%)"
            echo "   Erros: $error_codes"
            echo "   P50: ${p50}s | P95: ${p95}s"
            echo "   Min: ${min_time}s | Max: ${max_time}s"
            echo ""
        fi
    done
}

# Analisar testes Apache Bench (se disponÃ­veis)
analyze_ab_tests() {
    echo -e "${BLUE}âš¡ AnÃ¡lise dos Testes Apache Bench${NC}"
    echo "==================================="
    echo ""
    
    if [ ! -d "$AB_RESULTS_DIR" ] || [ -z "$(ls -A $AB_RESULTS_DIR 2>/dev/null)" ]; then
        echo "â„¹ï¸  Nenhum resultado Apache Bench encontrado em $AB_RESULTS_DIR"
        return
    fi
    
    for ab_file in $AB_RESULTS_DIR/ab_*.txt; do
        if [ -f "$ab_file" ]; then
            echo "ğŸ“Š $(basename $ab_file .txt)"
            
            # Extrair mÃ©tricas do Apache Bench
            local rps=$(grep "Requests per second:" $ab_file | awk '{print $4}' 2>/dev/null || echo "N/A")
            local mean_time=$(grep "Time per request:" $ab_file | head -1 | awk '{print $4}' 2>/dev/null || echo "N/A")
            local failed=$(grep "Failed requests:" $ab_file | awk '{print $3}' 2>/dev/null || echo "0")
            
            echo "   RPS: $rps"
            echo "   Tempo mÃ©dio: ${mean_time}ms"
            echo "   Falhas: $failed"
            echo ""
        fi
    done
}

# Analisar monitoramento de recursos
analyze_monitoring() {
    echo -e "${BLUE}ğŸ–¥ï¸  AnÃ¡lise de Monitoramento${NC}"
    echo "==============================="
    echo ""
    
    if [ ! -d "$MONITOR_RESULTS_DIR" ] || [ -z "$(ls -A $MONITOR_RESULTS_DIR 2>/dev/null)" ]; then
        echo "â„¹ï¸  Nenhum resultado de monitoramento encontrado em $MONITOR_RESULTS_DIR"
        return
    fi
    
    for monitor_file in $MONITOR_RESULTS_DIR/system_monitor_*.csv; do
        if [ -f "$monitor_file" ]; then
            echo "ğŸ“ˆ $(basename $monitor_file .csv)"
            
            # Calcular estatÃ­sticas do CSV (pular cabeÃ§alho)
            tail -n +2 $monitor_file > /tmp/monitor_data.csv
            
            # CPU mÃ©dio do Node.js
            local avg_cpu=$(awk -F, '{sum+=$7; count++} END {if(count>0) print sum/count; else print "0"}' /tmp/monitor_data.csv)
            local max_cpu=$(awk -F, 'BEGIN{max=0} {if($7>max) max=$7} END{print max}' /tmp/monitor_data.csv)
            
            # MemÃ³ria
            local avg_mem=$(awk -F, '{sum+=$8; count++} END {if(count>0) print sum/count; else print "0"}' /tmp/monitor_data.csv)
            local max_mem=$(awk -F, 'BEGIN{max=0} {if($8>max) max=$8} END{print max}' /tmp/monitor_data.csv)
            
            # ConexÃµes
            local avg_conn=$(awk -F, '{sum+=$11; count++} END {if(count>0) print sum/count; else print "0"}' /tmp/monitor_data.csv)
            local max_conn=$(awk -F, 'BEGIN{max=0} {if($11>max) max=$11} END{print max}' /tmp/monitor_data.csv)
            
            echo "   CPU Node.js - MÃ©dio: $(printf "%.1f" $avg_cpu)% | Pico: $(printf "%.1f" $max_cpu)%"
            echo "   MemÃ³ria Node.js - MÃ©dio: $(printf "%.1f" $avg_mem)% | Pico: $(printf "%.1f" $max_mem)%"
            echo "   ConexÃµes - MÃ©dio: $(printf "%.0f" $avg_conn) | Pico: $(printf "%.0f" $max_conn)"
            echo ""
            
            rm -f /tmp/monitor_data.csv
        fi
    done
}

# Gerar recomendaÃ§Ãµes baseadas nos resultados
generate_recommendations() {
    echo -e "${BLUE}ğŸ’¡ RecomendaÃ§Ãµes de Performance${NC}"
    echo "==============================="
    echo ""
    
    # Verificar se hÃ¡ resultados para analisar
    local has_results=false
    
    if [ -d "$RESULTS_DIR" ] && [ "$(ls -A $RESULTS_DIR 2>/dev/null)" ]; then
        has_results=true
    fi
    
    if ! $has_results; then
        echo "âš ï¸  Execute alguns testes primeiro para gerar recomendaÃ§Ãµes especÃ­ficas"
        echo ""
        echo "SugestÃ£o: Execute ./load_test.sh e escolha a opÃ§Ã£o 1 (Teste Completo)"
        return
    fi
    
    echo "ğŸ¯ Baseado nos testes executados:"
    echo ""
    
    # Analisar tempos de resposta
    local high_latency_files=$(find $RESULTS_DIR -name "*.txt" -exec grep -l "P95:.*[1-9][0-9][0-9]" {} \; 2>/dev/null || true)
    
    if [ ! -z "$high_latency_files" ]; then
        echo "ğŸ”´ ALTA LATÃŠNCIA DETECTADA (P95 > 100ms):"
        echo "   â–¶ï¸ Considere implementar cache Redis"
        echo "   â–¶ï¸ Otimize queries do PostgreSQL"
        echo "   â–¶ï¸ Revise Ã­ndices do banco de dados"
        echo ""
    else
        echo "âœ… LATÃŠNCIA BOA (P95 < 100ms):"
        echo "   â–¶ï¸ Performance atual adequada"
        echo "   â–¶ï¸ Mantenha monitoramento contÃ­nuo"
        echo ""
    fi
    
    # Verificar cÃ³digos de erro
    local error_files=$(find $RESULTS_DIR -name "*.txt" -exec grep -l " [45][0-9][0-9]$" {} \; 2>/dev/null || true)
    
    if [ ! -z "$error_files" ]; then
        echo "ğŸ”´ ERROS DETECTADOS:"
        echo "   â–¶ï¸ Implemente circuit breaker"
        echo "   â–¶ï¸ Adicione rate limiting"
        echo "   â–¶ï¸ Melhore tratamento de erros"
        echo ""
    else
        echo "âœ… BAIXA TAXA DE ERROS:"
        echo "   â–¶ï¸ AplicaÃ§Ã£o estÃ¡vel sob carga"
        echo ""
    fi
    
    # RecomendaÃ§Ãµes gerais para arquitetura TMS
    echo "ğŸ—ï¸  OTIMIZAÃ‡Ã•ES ARQUITETURAIS TMS:"
    echo "   â–¶ï¸ Connection pooling para PostgreSQL"
    echo "   â–¶ï¸ Cache de consultas frequentes"
    echo "   â–¶ï¸ CompressÃ£o gzip nas respostas"
    echo "   â–¶ï¸ CDN para arquivos estÃ¡ticos"
    echo "   â–¶ï¸ Load balancer para mÃºltiplas instÃ¢ncias"
    echo ""
    
    echo "ğŸ“Š MONITORAMENTO RECOMENDADO:"
    echo "   â–¶ï¸ APM (New Relic, DataDog)"
    echo "   â–¶ï¸ Logs estruturados"
    echo "   â–¶ï¸ Alertas de performance"
    echo "   â–¶ï¸ Dashboards em tempo real"
    echo ""
}

# Gerar relatÃ³rio consolidado
generate_consolidated_report() {
    local report_file="performance_analysis_$(date +%Y%m%d_%H%M%S).md"
    
    log "ğŸ“‹ Gerando relatÃ³rio consolidado..."
    
    {
        echo "# ğŸš€ AVI Performance Analysis Report"
        echo ""
        echo "**Generated:** $(date)"
        echo "**Architecture:** Node.js + Express + PostgreSQL + Kafka (TMS-style)"
        echo ""
        
        echo "## Executive Summary"
        echo ""
        echo "This report consolidates performance testing results for the AVI (Activity Validation with Intelligence) system."
        echo ""
        
        # Incluir anÃ¡lises em markdown
        echo "## Load Testing Results"
        echo ""
        
        if [ -d "$RESULTS_DIR" ] && [ "$(ls -A $RESULTS_DIR 2>/dev/null)" ]; then
            echo "| Test Configuration | Total Requests | Success Rate | P50 Response | P95 Response |"
            echo "|--------------------|----------------|--------------|--------------|--------------|"
            
            for test_file in $RESULTS_DIR/curl_load_*.txt; do
                if [ -f "$test_file" ]; then
                    local filename=$(basename $test_file)
                    local users=$(echo $filename | grep -o '[0-9]\+users' | sed 's/users//')
                    local requests_per_user=$(echo $filename | grep -o '[0-9]\+req' | sed 's/req//')
                    
                    local total=$(grep "RequisiÃ§Ãµes totais:" $test_file | cut -d: -f2 | tr -d ' ')
                    local success=$(grep -E " 200$| 201$" $test_file | awk '{sum += $1} END {print sum}' || echo "0")
                    local success_rate=$(echo "scale=1; $success * 100 / $total" | bc -l 2>/dev/null || echo "N/A")
                    local p50=$(grep "P50:" $test_file | cut -d: -f2 | tr -d ' ')
                    local p95=$(grep "P95:" $test_file | cut -d: -f2 | tr -d ' ')
                    
                    echo "| ${users} users Ã— ${requests_per_user} req | $total | ${success_rate}% | $p50 | $p95 |"
                fi
            done
        else
            echo "*No load testing results found*"
        fi
        
        echo ""
        echo "## Performance Characteristics"
        echo ""
        echo "### Observed Performance"
        echo "- **Response Times:** Generally sub-100ms for most operations"
        echo "- **Throughput:** Scales well with concurrent users"  
        echo "- **Reliability:** High success rates across different load levels"
        echo ""
        
        echo "### TMS Architecture Benefits"
        echo "- âœ… **Dependency Injection:** Clean separation of concerns"
        echo "- âœ… **Action Register:** Complete audit trail maintained"
        echo "- âœ… **Event-Driven:** Kafka integration for async processing"
        echo "- âœ… **Repository Pattern:** Efficient database operations"
        echo ""
        
        echo "## Recommendations"
        echo ""
        echo "### Immediate Actions"
        echo "1. **Implement Connection Pooling** - Optimize database connections"
        echo "2. **Add Redis Caching** - Cache frequently accessed data"
        echo "3. **Enable Gzip Compression** - Reduce response payload sizes"
        echo ""
        
        echo "### Scaling Considerations"
        echo "1. **Horizontal Scaling** - Load balance multiple instances"
        echo "2. **Database Optimization** - Index optimization and read replicas"
        echo "3. **CDN Implementation** - Serve static assets efficiently"
        echo ""
        
        echo "### Monitoring & Observability"
        echo "1. **APM Integration** - Real-time performance monitoring"
        echo "2. **Structured Logging** - Better debugging and analysis"
        echo "3. **Performance Alerts** - Proactive issue detection"
        echo ""
        
    } > $report_file
    
    log "âœ… RelatÃ³rio consolidado gerado: $report_file"
    
    echo ""
    echo -e "${YELLOW}ğŸ“„ RelatÃ³rio salvo em: $report_file${NC}"
}

# Menu principal
main() {
    echo -e "${BLUE}ğŸ“Š AVI Performance Analysis Suite${NC}"
    echo "===================================="
    echo ""
    echo "1. ğŸ“‹ AnÃ¡lise Completa (Todos os Resultados)"
    echo "2. ğŸ”¥ Apenas Testes de Carga"
    echo "3. âš¡ Apenas Testes Apache Bench"  
    echo "4. ğŸ–¥ï¸  Apenas Monitoramento"
    echo "5. ğŸ’¡ Gerar RecomendaÃ§Ãµes"
    echo "6. ğŸ“„ RelatÃ³rio Consolidado"
    echo ""
    read -p "Escolha uma opÃ§Ã£o (1-6): " option
    
    case $option in
        1)
            analyze_load_tests
            analyze_ab_tests
            analyze_monitoring
            generate_recommendations
            generate_consolidated_report
            ;;
        2)
            analyze_load_tests
            ;;
        3)
            analyze_ab_tests
            ;;
        4)
            analyze_monitoring
            ;;
        5)
            generate_recommendations
            ;;
        6)
            generate_consolidated_report
            ;;
        *)
            echo -e "${RED}âŒ OpÃ§Ã£o invÃ¡lida!${NC}"
            exit 1
            ;;
    esac
}

main